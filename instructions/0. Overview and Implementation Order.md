
# Reverie — Implementation Overview

## Project Vision
A self-hosted, Google Drive-like application with advanced OCR and LLM capabilities for organizing, searching, and understanding document collections. Optimized for financial documents but extensible to any document type.

---

## Core Features
1. **File Storage**: Self-hosted on Linux machine, S3 compatible
2. **OCR Processing**: Extract text from images, parse structured metadata
3. **Smart Categorization**: Auto-classify documents by type
4. **LLM Enhancement**: Generate document summaries and extract structured metadata
5. **Advanced Search**: Full-text search with filters (date, category, entity, etc.)
6. **Thumbnails + BlurHash**: Multiple sizes + instant placeholders for smooth loading
7. **Cross-Platform**: Web app (desktop) and Native Android (mobile)

---

## Technology Stack Summary

### Backend
- **Runtime**: Node.js + TypeScript
- **Framework**: Fastify
- **Database**: PostgreSQL + Kysely (type-safe SQL)
- **Validation**: Zod schemas
- **Job Queue**: BullMQ + Redis
- **Real-Time**: Socket.io (WebSockets) + Redis pub/sub
- **OCR**: Tesseract.js
- **LLM**: OpenAI API (GPT-4o-mini)
- **Storage**: Abstracted (Local FS + S3-compatible)
- **Images**: sharp (thumbnails), blurhash (placeholders)

### Frontend
- **Web App**: React + Vite + TypeScript
- **Android App**: Kotlin + Jetpack Compose (Material Design 3)
- **Styling**: 
  - Web: CSS Modules or Tailwind
  - Android: Material You with dynamic color
- **Testing**: Vitest (web), JUnit + Compose Testing (Android)

### Monorepo
- **Tool**: Nx
- **Package Manager**: pnpm
- **Projects**: backend, apps/web, apps/android (Gradle), shared

---

## Implementation Plans

### Phase 1: Foundation
**Plan 01 — Initial Monorepo Setup**
- Set up Nx workspace
- Create backend, client, shared projects
- Configure TypeScript, ESLint, build tools
- Status: Not started

**Plan 02 — Backend Architecture, API Contracts, and Database Layer**
- Fastify API setup
- PostgreSQL + Kysely schema
- Zod API contracts in shared package
- Storage abstraction layer (Local + S3)
- Search infrastructure basics
- Status: Not started

**Plan 03 — Client Setup (Web App + Native Android)**
- Web app with React + Vite
- Android app with Kotlin + Jetpack Compose
- OpenAPI-based shared contracts
- Landing screens for both platforms
- Status: Not started

---

### Phase 2: Core Features
**Plan 04 — Job Queue and Worker Architecture**
- BullMQ + Redis setup
- Worker processes for OCR, thumbnails, LLM
- Job status tracking
- Retry logic and error handling
- WebSocket real-time progress updates (Socket.io + Redis pub/sub)
- Status: Not started

**Plan 05 — OCR Pipeline**
- Tesseract integration
- Image preprocessing
- Metadata extraction (dates, companies, values)
- Document categorization
- Full-text search indexing
- Status: Not started

**Plan 06 — LLM Integration for Document Processing**
- OpenAI API client
- Document-level summaries and metadata extraction
- Generic prompts for diverse document types
- Token usage tracking
- Iterative development approach
- Status: Not started

**Plan 07 — Advanced Search Implementation**
- Query parser (syntax: `category:X date:Y "text"`)
- PostgreSQL full-text search
- Faceted filtering
- Autocomplete/suggestions
- Result highlighting
- Status: Not started

---

## Suggested Implementation Order

### Sprint 1: Scaffolding (1-2 weeks)
1. Plan 01 — Monorepo setup
2. Plan 02 — Backend basics (no storage/search yet)
3. Plan 03 — Client basics (landing screen only)

**Goal**: Everything builds, health endpoint works, basic UI renders

---

### Sprint 2: Storage & Upload (1-2 weeks)
1. Plan 02 (continued) — Storage abstraction layer
2. Implement file upload API endpoint
3. Basic file browsing in client
4. Thumbnail generation (optional)

**Goal**: User can upload images, view folder structure

---

### Sprint 3: Async Jobs & OCR (2-3 weeks)
1. Plan 04 — Job queue setup + WebSocket real-time updates
2. Plan 05 — OCR pipeline
3. Display OCR results in client with live progress

**Goal**: Uploaded images are processed, text is extracted and searchable, with real-time progress feedback

---

### Sprint 4: Search (1-2 weeks)
1. Plan 07 — Search implementation
2. Search UI in client
3. Filters and facets

**Goal**: User can search documents by content, date, category

---

### Sprint 5: LLM Document Enhancement (1-2 weeks)
1. Plan 06 — LLM integration
2. Document summary display in UI
3. Enhanced metadata for search
4. Manual reprocessing

**Goal**: Documents have LLM-generated summaries and enriched metadata for better search

---

### Sprint 6: Polish & Features (ongoing)
- Bulk upload improvements
- Better metadata extraction
- User tagging system
- Folder management (move, rename, delete)
- Settings page
- Mobile app testing and refinement

---

## Key Design Decisions

### Why Separate Web + Android Apps?
- Native Android (Jetpack Compose) gives best mobile UX
- Web app is simpler and faster than Electron
- Material You theming on Android
- **Tradeoff**: Two codebases, no iOS initially

### Why Postgres over Separate Search Service?
- Built-in full-text search is fast enough for moderate scale
- Reduces infrastructure complexity
- Can add pgvector for semantic search later
- **Future**: Migrate to Meilisearch/Typesense if needed

### Why BullMQ over Simpler Queue?
- Production-ready with retries, priorities, monitoring
- Redis can also serve as cache
- Bull Board for job dashboard
- **Alternative**: Graphile Worker (Postgres-based, no Redis) if Redis unwanted

### Why Zod over Other Validators?
- Type inference (no duplicate type definitions)
- Runtime validation = compile-time types
- Can generate OpenAPI schemas
- Shared between frontend and backend

### Why Tesseract over Cloud OCR?
- Free, no API limits
- Runs locally (privacy)
- Good enough for scanned documents
- **Future**: Add cloud OCR for handwriting/complex layouts

---

## Database Schema Highlights

### Core Tables
- **folders**: Hierarchical folder structure (with user-written descriptions)
- **documents**: File metadata, category, extracted date, LLM summary & metadata
- **ocr_results**: Full text, metadata (companies, values), search vector
- **processing_jobs**: Async job tracking
- **document_tags**: User and auto-generated tags

### Key Indexes
- GIN index on `ocr_results.text_vector` (full-text search)
- B-tree on `documents.extracted_date` (date range queries)
- B-tree on `documents.file_hash` (deduplication)

---

## Development Workflow

### Running the App (after setup)
```bash
# Start PostgreSQL and Redis
docker-compose up -d

# Backend (includes WebSocket server)
cd backend
pnpm run dev

# Workers (separate terminals)
pnpm run worker:ocr
pnpm run worker:llm

# Web client
cd apps/web
pnpm dev

# Android client
cd apps/android
./gradlew installDebug
```

---

## Testing Strategy

### Backend
- Unit tests for services (storage, OCR, LLM) with Vitest
- Integration tests for API endpoints
- Test database setup (separate from dev DB)

### Client
- Web: Vitest + React Testing Library, Playwright for E2E
- Android: JUnit + Compose Testing, Espresso for E2E

### OCR Quality
- Test suite of sample images with known ground truth
- Measure accuracy and confidence scores

---

## Deployment (Future)

### Backend
- Docker container
- systemd service on Linux machine
- Nginx reverse proxy (SSL termination)

### Workers
- Separate Docker containers
- Scaled independently based on load

### Client
- **Web**: Static files served via Nginx or S3
- **Android**: APK/AAB via GitHub Actions → Play Store or direct download

---

## Known Limitations & Future Work

### Current Scope (MVP)
- Images only (no PDFs, videos, music yet)
- Single user (no auth/multi-tenancy)
- English-only OCR
- OpenAI API dependency for LLM

### Future Enhancements
- Multi-user support with authentication
- PDF support (multi-page documents)
- Video and music metadata extraction
- Local LLM option (Ollama, llama.cpp)
- Semantic search with embeddings
- Mobile offline mode
- Shared folders / collaboration
- File versioning

---

## Cost Estimates

### Infrastructure
- **Storage**: Free (self-hosted)
- **Compute**: Free (self-hosted Linux machine)
- **Database**: Free (PostgreSQL on same machine)
- **Redis**: Free (on same machine)

### API Costs
- **OpenAI**: ~$0.15 per 1M input tokens, ~$0.60 per 1M output tokens (GPT-4o-mini)
  - Example: 100 document summaries/month (~150k tokens total) ≈ $0.10/month
  - 1000 documents/month ≈ $1.00/month
- **OCR**: Free (Tesseract)

**Total**: <$5/month for moderate usage (hundreds of documents)

---

## Success Metrics (Post-MVP)

1. **Upload speed**: <5s for batch of 10 images
2. **OCR accuracy**: >90% for printed text
3. **Search speed**: <100ms for most queries
4. **Summary quality**: User finds summary helpful >80% of time
5. **Cross-platform parity**: All features work on web and Android

---

## Questions to Resolve Later

1. **OCR model tuning**: Should we train custom Tesseract models for financial docs?
2. **LLM prompt optimization**: A/B test different summary prompts?
3. **Storage scaling**: When to migrate from local FS to object storage?
4. **Search scaling**: When to migrate from Postgres to dedicated search engine?
5. **Mobile sync**: Should mobile app have local cache + sync, or always online?

---

## Getting Started

**Next Step**: Implement Plan 01 (Monorepo Setup)

See `1. Initial setup.md` for detailed instructions.


