
# Plan 05 — OCR Pipeline

## Goal
Implement automated OCR processing for uploaded images:
- Extract text from documents
- Parse structured metadata (dates, values, categories)
- Store results for search and LLM processing
- Handle batch uploads efficiently

---

## Core Principles
- OCR runs asynchronously via job queue
- Results are structured and searchable
- Confidence scores tracked for quality control
- Handles multiple image formats
- Fails gracefully on poor-quality images

---

## Technology Stack
- OCR Engine: **Tesseract** (via `tesseract.js` for Node.js)
- Image Processing: **sharp** (resizing, format conversion, preprocessing)
- Text Parsing: Custom logic + regex patterns
- Storage: `ocr_results` table

---

## OCR Workflow

### 1. Pre-processing
Before OCR, images are optimized:
- Convert to grayscale (improves accuracy)
- Increase contrast
- Resize if too large (max 2000px width)
- Remove noise

### 2. Text Extraction
- Run Tesseract on preprocessed image
- Get raw text + confidence score
- Store full OCR output

### 3. Metadata Extraction
Parse structured data from text:
- **Dates**: Regex patterns for common formats (MM/DD/YYYY, DD.MM.YYYY, etc)
- **Companies**: Pattern matching + list of known entities
- **Values**: E.g. Currency amounts, stock quantities, percentages
- **Categories**: Document type classification

### 4. Storage
- Save to `ocr_results` table
- Update `documents.ocr_status = 'complete'`
- Generate full-text search vector

---

## Folder Structure

```
backend/
  src/
    ocr/
      ocr.service.ts          // Main OCR orchestration
      tesseract.client.ts     // Tesseract wrapper
      image-preprocessor.ts   // Image optimization
      metadata-extractor.ts   // Parse structured data
      patterns.ts             // Regex patterns for extraction

    workers/
      ocr.worker.ts           // Job queue worker (from Plan 04)
```

---

## OCR Service Interface

```typescript
interface OcrService {
  processDocument(documentId: string): Promise<OcrResult>
  extractMetadata(text: string): ExtractedMetadata
  classifyDocument(text: string, metadata: ExtractedMetadata): DocumentCategory
}

interface OcrResult {
  raw_text: string
  confidence_score: number
  metadata: ExtractedMetadata
  category: DocumentCategory
}

interface ExtractedMetadata {
  dates: Date[]
  primary_date?: Date  // Best guess for "document date"
  companies: string[]
  currency_values: { amount: number, currency: string }[]
  stock_quantities: number[]
  percentages: number[]
}

type DocumentCategory = 
  | 'stock_overview' 
  | 'stock_split' 
  | 'dividend_statement'
  | 'transaction_receipt'
  | 'other'
```

---

## Metadata Extraction Rules

### Date Detection
Priority order:
1. Top-right corner text (common for financial docs)
2. Header lines
3. Any date in format MM/DD/YYYY or DD.MM.YYYY
4. Fallback: use document upload date

### Company Extraction
- Match against known stock tickers (AAPL, GOOGL, etc)
- Pattern: "Company Name Inc.", "X Corporation"
- Store all mentions, rank by frequency

### Value Extraction
- Currency: `$1,234.56`, `USD 1234.56`, `€1.234,56`
- Stock quantities: Numbers near keywords "shares", "units", "qty"
- Percentages: `12.5%`, `0.05%`

### Category Classification
Simple keyword-based rules:
- "stock split" → `stock_split`
- "dividend", "DPS" → `dividend_statement`
- "portfolio", "holdings" → `stock_overview`
- "transaction", "trade" → `transaction_receipt`
- Default: `other`

---

## Error Handling

### Low Confidence OCR
If Tesseract confidence < 60%:
- Store result but flag in UI
- Suggest manual review
- Allow user to re-process with different settings

### Extraction Failures
If no metadata extracted:
- Still store raw text (useful for search)
- Category defaults to `other`
- Don't block document save

### Invalid Images
- Corrupted files
- Non-image files
- Encrypted/password-protected PDFs (future)

Mark job as `failed`, log error, notify user.

---

## Performance Considerations

### Batch Processing
For bulk uploads (100+ images):
- Process in parallel (configurable concurrency)
- Use job priority: user-triggered > batch
- Progress tracking via job status

### Caching
- Cache preprocessed images (optional)
- Cache Tesseract model loads (loaded once per worker)

### Resource Limits
- Max image size: 10MB (reject larger)
- Max processing time: 30s per image
- Timeout and retry if exceeded

---

## Integration with Job Queue

OCR Worker flow:
```typescript
async function processOcrJob(job: Job<OcrJobData>) {
  const { documentId } = job.data
  
  // 1. Fetch document from DB
  const doc = await db.selectFrom('documents').where('id', '=', documentId).selectAll().executeTakeFirst()
  
  // 2. Load image from storage
  const imageBuffer = await storageService.retrieve(doc.file_path)
  
  // 3. Preprocess
  const processedImage = await preprocessImage(imageBuffer)
  
  // 4. OCR
  const ocrResult = await tesseractClient.recognize(processedImage)
  
  // 5. Extract metadata
  const metadata = await metadataExtractor.extract(ocrResult.text)
  
  // 6. Classify
  const category = classifyDocument(ocrResult.text, metadata)
  
  // 7. Save to DB
  await saveOcrResult(documentId, {
    raw_text: ocrResult.text,
    confidence_score: ocrResult.confidence,
    metadata,
  })
  
  await updateDocumentCategory(documentId, category)
  
  // 8. Update job status
  return { success: true, confidence: ocrResult.confidence }
}
```

---

## Search Integration

After OCR completion, update full-text search:
```sql
-- Trigger updates tsvector automatically
UPDATE ocr_results 
SET text_vector = to_tsvector('english', raw_text)
WHERE document_id = :documentId;
```

---

## API Endpoints (Exposed by routes)

### Trigger OCR
```
POST /api/documents/:id/ocr
Response: { job_id: string, status: 'pending' }
```

### Get OCR Result
```
GET /api/documents/:id/ocr
Response: { raw_text, confidence_score, metadata, category }
```

### Re-process OCR
```
POST /api/documents/:id/ocr/retry
```

---

## Acceptance Criteria
- Tesseract is installed and accessible
- OCR worker processes jobs successfully
- Text extraction works on sample images
- Metadata extraction finds dates and companies
- Results stored in `ocr_results` table
- Full-text search vector is generated
- Document category is automatically assigned
- Failed OCR attempts are logged and retried

---

## Future Enhancements
- PDF support (multi-page documents)
- Handwriting recognition (Tesseract LSTM models)
- Custom model training for specific document types
- OCR quality scoring and auto-retry
- User feedback loop (correct wrong extractions)



